# üöÄ WatsonX Integration v√† Deployment Guide cho LightRAG

## üìã **T·ªïng quan**

T√†i li·ªáu n√†y m√¥ t·∫£ chi ti·∫øt qu√° tr√¨nh t√≠ch h·ª£p IBM WatsonX v·ªõi LightRAG framework, bao g·ªìm:
- ‚úÖ WatsonX LLM integration v·ªõi detailed token tracking
- ‚úÖ Docker containerization v·ªõi optimized builds  
- ‚úÖ Private registry deployment workflow
- ‚úÖ Production-ready configuration

---

## üéØ **C√°c t√≠nh nƒÉng ƒë√£ tri·ªÉn khai**

### 1. **WatsonX LLM Integration**
- ‚úÖ **Async API calls** v·ªõi retry mechanism
- ‚úÖ **Token authentication** v·ªõi auto-refresh  
- ‚úÖ **Detailed token tracking** t·ª´ WatsonX API response
- ‚úÖ **Comprehensive error handling** v·ªõi response format detection
- ‚úÖ **Performance monitoring** v·ªõi timing v√† throughput tracking

### 2. **TokenTracker System** 
- ‚úÖ **Real-time monitoring** c·ªßa prompt/completion/total tokens
- ‚úÖ **API timing tracking** (total time vs API call time)
- ‚úÖ **Operation type classification** (entity_extraction, relationship_extraction, etc.)
- ‚úÖ **Performance metrics** (tokens per second, cost estimation)
- ‚úÖ **Detailed logging** cho m·ªói WatsonX API call

### 3. **Docker Optimization**
- ‚úÖ **Dockerfile.optimized** - build time 2-3 ph√∫t (vs 5-10 ph√∫t b·∫£n g·ªëc)
- ‚úÖ **Multi-stage builds** v·ªõi security best practices
- ‚úÖ **Volume optimization** v·ªõi proper permissions
- ‚úÖ **Registry workflow** cho production deployment

---

## üìÅ **Files ƒë√£ t·∫°o/ch·ªânh s·ª≠a**

### **Core LLM Integration:**
```
lightrag/llm/watsonx.py                     # WatsonX LLM implementation
lightrag/api/lightrag_server.py             # Server integration v·ªõi TokenTracker
lightrag/utils.py                           # Enhanced TokenTracker class
```

### **Docker v√† Deployment:**
```
Dockerfile.optimized                        # Optimized Docker build
docker-compose.registry.yml                 # Registry deployment config  
build_and_push.ps1                         # PowerShell build script
BUILD_SCRIPT_USAGE.md                      # Build script documentation
```

### **Demo v√† Examples:**
```
examples/lightrag_watsonx_track_token_demo.py    # TokenTracker demo
examples/detailed_timing_demo.py                  # Timing analysis demo
examples/timing_analyzer.py                       # Statistical analysis tool
```

---

## ‚öôÔ∏è **C·∫•u h√¨nh Environment Variables**

### **WatsonX API Configuration:**
```bash
# Required - WatsonX API credentials
WATSONX_API_KEY=your_watsonx_api_key
WATSONX_PROJECT_ID=your_project_id
WATSONX_BASE_URL=https://us-south.ml.cloud.ibm.com/ml/v1

# Optional - Model configuration
WATSONX_MODEL_ID=openai/gpt-oss-120b
LLM_BINDING=watsonx

# Optional - Performance tuning
MAX_TOKENS=8000
TEMPERATURE=0.7
```

### **LightRAG Server Configuration:**
```bash
# Server settings
PORT=9621
WORKING_DIR=/app/data
WORKSPACE=default

# Performance settings  
MAX_ASYNC=8
CHUNK_SIZE=1200
CHUNK_OVERLAP_SIZE=100
```

---

## üöÄ **Deployment Workflows**

### **1. Local Development**
```powershell
# Build local
docker build -f Dockerfile.optimized -t lightrag_watsonx:local .

# Run v·ªõi environment variables
docker run -d --name lightrag-local `
  -p 9621:9621 `
  -e WATSONX_API_KEY=$env:WATSONX_API_KEY `
  -e WATSONX_PROJECT_ID=$env:WATSONX_PROJECT_ID `
  -v ${PWD}/data:/app/data `
  -v ${PWD}/.env:/app/.env `
  --user 0:0 `
  lightrag_watsonx:local
```

### **2. Production Registry Deployment**
```powershell
# Build v√† push l√™n private registry
.\build_and_push.ps1 -Tag "v1.3.1" -NoCache

# Tr√™n server - deploy t·ª´ registry  
docker-compose -f docker-compose.registry.yml pull
docker-compose -f docker-compose.registry.yml up -d
```

---

## üìä **Token Tracking Output**

### **Logs m·∫´u khi TokenTracker ho·∫°t ƒë·ªông:**
```
INFO: WatsonX LLM initialized with model: openai/gpt-oss-120b
INFO: TokenTracker enabled for WatsonX API monitoring
INFO: Making request to WatsonX: https://us-south.ml.cloud.ibm.com/ml/v1/text/chat
INFO: WatsonX API timing - Total: 12.20s, API Call: 11.46s
INFO: ‚úÖ Token usage found: Prompt=4868, Completion=1234, Total=6102
INFO: WatsonX Token Usage - Model: openai/gpt-oss-120b, Operation: entity_extraction, Time: 12.20s, Prompt: 4868, Completion: 1234, Total: 6102, Speed: 500.2 tokens/s
```

### **Th√¥ng tin chi ti·∫øt ƒë∆∞·ª£c track:**
- **Prompt tokens**: S·ªë token input t·ª´ LightRAG
- **Completion tokens**: S·ªë token ƒë∆∞·ª£c WatsonX generate  
- **Total tokens**: T·ªïng token usage cho billing
- **API timing**: Th·ªùi gian total vs pure API call
- **Throughput**: Tokens per second performance
- **Operation type**: entity_extraction, relationship_extraction, etc.

---

## üîß **Troubleshooting**

### **1. TokenTracker kh√¥ng hi·ªÉn th·ªã logs**
```bash
# Check debug logs
INFO: üîç SERVER DEBUG: TokenTracker available: False  # ‚Üê V·∫•n ƒë·ªÅ ·ªü ƒë√¢y

# Solutions:
1. Rebuild container v·ªõi latest code
2. Verify .env variables ƒë∆∞·ª£c load
3. Check container logs cho startup errors
```

### **2. WatsonX API Response Format Issues**
```bash
# Check response structure logs
INFO: WatsonX response keys: ['id', 'object', 'model_id', 'model', 'choices', ...]
ERROR: choices[0].message keys: ['role']  # ‚Üê Missing content

# Solutions:
1. Increase max_tokens (default: 8000)  
2. Check prompt format compatibility
3. Verify WatsonX model availability
```

### **3. Docker Volume Permission Issues**
```bash
ERROR: [Errno 13] Permission denied: '/app/data/rag_storage/kv_store_doc_status.json'

# Solutions:
1. Add user: "0:0" v√†o docker-compose.yml
2. Fix host directory permissions: sudo chown -R 1000:1000 ./data/
3. Use Docker volumes thay v√¨ bind mounts
```

---

## üèóÔ∏è **Technical Architecture**

### **WatsonX Integration Flow:**
```
LightRAG Request
    ‚Üì
lightrag_server.py (watsonx_model_complete)
    ‚Üì 
watsonx_llm_acomplete() with TokenTracker
    ‚Üì
WatsonXLLM.acompletion() with timing
    ‚Üì
IBM WatsonX API Call
    ‚Üì
Response parsing + Token tracking
    ‚Üì
TokenTracker.add_usage() v·ªõi detailed metrics
    ‚Üì
Return processed response
```

### **Key Components:**

#### **WatsonXLLM Class (`lightrag/llm/watsonx.py`)**
- Handles authentication v·ªõi IBM IAM
- Retry mechanism cho API reliability  
- Comprehensive response format handling
- Detailed timing v√† token usage tracking

#### **TokenTracker Class (`lightrag/utils.py`)**  
- Real-time token usage monitoring
- Statistical analysis v√† performance metrics
- Cost estimation v√† optimization insights
- Per-operation tracking v√† classification

#### **Server Integration (`lightrag/api/lightrag_server.py`)**
- TokenTracker initialization v√† injection
- Global args management cho cross-function access
- Debug logging cho troubleshooting

---

## üìà **Performance Metrics**

### **Observed Performance:**
- **Entity Extraction**: ~200-500 tokens/second
- **Relationship Extraction**: ~300-600 tokens/second  
- **API Latency**: 10-30 seconds per call (depending on complexity)
- **Build Time**: 2-3 minutes (optimized) vs 5-10 minutes (standard)

### **Cost Optimization:**
- Real-time token usage tracking cho budget control
- Performance metrics cho optimization identification
- Operation-type classification cho cost analysis
- Detailed timing cho infrastructure planning

---

## üîê **Security Best Practices**

### **API Key Management:**
- ‚úÖ Environment variables thay v√¨ hardcoded keys
- ‚úÖ .env files kh√¥ng commit v√†o git  
- ‚úÖ Container secrets management trong production
- ‚úÖ Access token auto-refresh mechanism

### **Container Security:**
- ‚úÖ Non-root user trong production (khi c√≥ th·ªÉ)
- ‚úÖ Minimal base image v·ªõi security updates
- ‚úÖ Network isolation v·ªõi proper firewall rules
- ‚úÖ Registry scanning cho vulnerabilities

---

## üéØ **Production Deployment Checklist**

### **Pre-deployment:**
- [ ] WatsonX API credentials configured
- [ ] Environment variables properly set
- [ ] Docker registry access verified  
- [ ] Volume permissions configured
- [ ] Network connectivity tested

### **Deployment:**
- [ ] Build v√† push image th√†nh c√¥ng
- [ ] Container starts without errors
- [ ] TokenTracker logs xu·∫•t hi·ªán  
- [ ] API calls work properly
- [ ] Performance metrics within expectations

### **Post-deployment:**
- [ ] Monitor logs cho errors
- [ ] Verify token usage tracking
- [ ] Check performance metrics
- [ ] Test document processing workflow
- [ ] Backup data directories

---

## üìö **Additional Resources**

### **Documentation Files:**
- `BUILD_SCRIPT_USAGE.md` - Chi ti·∫øt v·ªÅ build script
- `examples/` - Demo code v√† usage examples  
- `docker-compose.registry.yml` - Production deployment config

### **Monitoring Tools:**
- `examples/timing_analyzer.py` - Performance analysis
- Container logs v·ªõi detailed token tracking
- WatsonX API usage dashboard (external)

---

## ‚úÖ **Conclusion**

Deployment n√†y cung c·∫•p:
- **Production-ready** WatsonX integration v·ªõi LightRAG
- **Comprehensive monitoring** v·ªõi detailed token tracking
- **Optimized performance** v·ªõi fast Docker builds
- **Scalable architecture** cho enterprise deployment
- **Complete observability** v·ªõi timing v√† cost metrics

**Next Steps:**
1. Deploy l√™n production environment
2. Monitor performance v√† cost metrics  
3. Scale based on usage patterns
4. Optimize prompts based on token analysis
5. Implement cost alerts v√† budgeting

---

**üìù Document Version:** 1.0  
**üìÖ Last Updated:** August 2025  
**üë§ Author:** AI Assistant v·ªõi LightRAG + WatsonX Integration  
**üè∑Ô∏è Tags:** #WatsonX #LightRAG #Docker #TokenTracking #Production